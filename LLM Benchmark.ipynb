{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb915985",
   "metadata": {},
   "source": [
    "LLM Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a85cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Top 10 Models per NLP Task by trending_score and downloads\n",
      "======================================================================\n",
      "\n",
      "ðŸ“‹ Text Classification  (tag: zero-shot-classification)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. facebook/bart-large-mnli\n",
      "   2. sileod/deberta-v3-base-tasksource-nli\n",
      "   3. MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "   4. joeddav/xlm-roberta-large-xnli\n",
      "   5. joeddav/bart-large-mnli-yahoo-answers\n",
      "   6. MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\n",
      "   7. vicgalle/xlm-roberta-large-xnli-anli\n",
      "   8. valhalla/distilbart-mnli-12-1\n",
      "   9. cross-encoder/nli-deberta-v3-large\n",
      "   10. MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\n",
      "Top 10 by trending_score:\n",
      "   1. facebook/bart-large-mnli\n",
      "   2. MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "   3. joeddav/xlm-roberta-large-xnli\n",
      "   4. MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\n",
      "   5. claritylab/zero-shot-explicit-binary-bert\n",
      "   6. MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\n",
      "   7. tasksource/ModernBERT-base-nli\n",
      "   8. ClaudeYang/awesome_fb_model\n",
      "   9. Jiva/xlm-roberta-large-it-mnli\n",
      "   10. KheireddineDaouadi/ZeroAraElectra\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. facebook/bart-large-mnli\n",
      "   2. sileod/deberta-v3-base-tasksource-nli\n",
      "   3. MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\n",
      "   4. joeddav/xlm-roberta-large-xnli\n",
      "   5. joeddav/bart-large-mnli-yahoo-answers\n",
      "   6. MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\n",
      "   7. vicgalle/xlm-roberta-large-xnli-anli\n",
      "   8. valhalla/distilbart-mnli-12-1\n",
      "   9. cross-encoder/nli-deberta-v3-large\n",
      "   10. MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\n",
      "   11. MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\n",
      "   12. claritylab/zero-shot-explicit-binary-bert\n",
      "   13. MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\n",
      "   14. tasksource/ModernBERT-base-nli\n",
      "   15. ClaudeYang/awesome_fb_model\n",
      "   16. Jiva/xlm-roberta-large-it-mnli\n",
      "   17. KheireddineDaouadi/ZeroAraElectra\n",
      "\n",
      "ðŸ“‹ Named Entity Recognition (NER) OR Part-of-Speech Tagging (POS)  (tag: token-classification)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. w11wo/indonesian-roberta-base-posp-tagger\n",
      "   2. dbmdz/bert-large-cased-finetuned-conll03-english\n",
      "   3. dslim/bert-base-NER\n",
      "   4. adibvafa/CodonTransformer\n",
      "   5. oliverguhr/fullstop-punctuation-multilang-large\n",
      "   6. tsmatz/xlm-roberta-ner-japanese\n",
      "   7. kredor/punctuate-all\n",
      "   8. cahya/NusaBert-ner-v1.3\n",
      "   9. OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M\n",
      "   10. Isotonic/distilbert_finetuned_ai4privacy_v2\n",
      "Top 10 by trending_score:\n",
      "   1. dslim/bert-base-NER\n",
      "   2. OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M\n",
      "   3. Babelscape/wikineural-multilingual-ner\n",
      "   4. CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy\n",
      "   5. Jean-Baptiste/camembert-ner\n",
      "   6. KoichiYasuoka/roberta-base-english-upos\n",
      "   7. KoichiYasuoka/roberta-large-english-upos\n",
      "   8. cahya/bert-base-indonesian-NER\n",
      "   9. jiaqianjing/chinese-address-ner\n",
      "   10. dslim/bert-large-NER\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. w11wo/indonesian-roberta-base-posp-tagger\n",
      "   2. dbmdz/bert-large-cased-finetuned-conll03-english\n",
      "   3. dslim/bert-base-NER\n",
      "   4. adibvafa/CodonTransformer\n",
      "   5. oliverguhr/fullstop-punctuation-multilang-large\n",
      "   6. tsmatz/xlm-roberta-ner-japanese\n",
      "   7. kredor/punctuate-all\n",
      "   8. cahya/NusaBert-ner-v1.3\n",
      "   9. OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M\n",
      "   10. Isotonic/distilbert_finetuned_ai4privacy_v2\n",
      "   11. OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M\n",
      "   12. Babelscape/wikineural-multilingual-ner\n",
      "   13. CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy\n",
      "   14. Jean-Baptiste/camembert-ner\n",
      "   15. KoichiYasuoka/roberta-base-english-upos\n",
      "   16. KoichiYasuoka/roberta-large-english-upos\n",
      "   17. cahya/bert-base-indonesian-NER\n",
      "   18. jiaqianjing/chinese-address-ner\n",
      "   19. dslim/bert-large-NER\n",
      "\n",
      "ðŸ“‹ Sentiment Analysis  (tag: text-classification)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "   2. distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "   3. BAAI/bge-reranker-v2-m3\n",
      "   4. facebook/roberta-hate-speech-dynabench-r4-target\n",
      "   5. nlptown/bert-base-multilingual-uncased-sentiment\n",
      "   6. microsoft/deberta-large-mnli\n",
      "   7. ProsusAI/finbert\n",
      "   8. j-hartmann/emotion-english-distilroberta-base\n",
      "   9. cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
      "   10. tomh/toxigen_hatebert\n",
      "Top 10 by trending_score:\n",
      "   1. tabularisai/multilingual-sentiment-analysis\n",
      "   2. BAAI/bge-reranker-v2-m3\n",
      "   3. ProsusAI/finbert\n",
      "   4. cardiffnlp/twitter-roberta-base-sentiment\n",
      "   5. j-hartmann/emotion-english-distilroberta-base\n",
      "   6. qualifire/prompt-injection-jailbreak-sentinel-v2\n",
      "   7. cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "   8. Skywork/Skywork-Reward-V2-Qwen3-8B\n",
      "   9. IMSyPP/hate_speech_en\n",
      "   10. nlptown/bert-base-multilingual-uncased-sentiment\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "   2. distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
      "   3. BAAI/bge-reranker-v2-m3\n",
      "   4. facebook/roberta-hate-speech-dynabench-r4-target\n",
      "   5. nlptown/bert-base-multilingual-uncased-sentiment\n",
      "   6. microsoft/deberta-large-mnli\n",
      "   7. ProsusAI/finbert\n",
      "   8. j-hartmann/emotion-english-distilroberta-base\n",
      "   9. cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
      "   10. tomh/toxigen_hatebert\n",
      "   11. tabularisai/multilingual-sentiment-analysis\n",
      "   12. cardiffnlp/twitter-roberta-base-sentiment\n",
      "   13. qualifire/prompt-injection-jailbreak-sentinel-v2\n",
      "   14. Skywork/Skywork-Reward-V2-Qwen3-8B\n",
      "   15. IMSyPP/hate_speech_en\n",
      "\n",
      "ðŸ“‹ Semantic Analysis  (tag: sentence-similarity)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. sentence-transformers/all-MiniLM-L6-v2\n",
      "   2. sentence-transformers/all-mpnet-base-v2\n",
      "   3. sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "   4. sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "   5. sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "   6. sentence-transformers/all-MiniLM-L12-v2\n",
      "   7. nomic-ai/nomic-embed-text-v1.5\n",
      "   8. Alibaba-NLP/gte-large-en-v1.5\n",
      "   9. upskyy/bge-m3-korean\n",
      "   10. Alibaba-NLP/gte-multilingual-base\n",
      "Top 10 by trending_score:\n",
      "   1. sentence-transformers/all-MiniLM-L6-v2\n",
      "   2. tencent/Youtu-Embedding\n",
      "   3. sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "   4. sentence-transformers/all-mpnet-base-v2\n",
      "   5. nomic-ai/nomic-embed-text-v1.5\n",
      "   6. ibm-granite/granite-embedding-125m-english\n",
      "   7. ibm-granite/granite-embedding-278m-multilingual\n",
      "   8. sentence-transformers/stsb-xlm-r-multilingual\n",
      "   9. Alibaba-NLP/gte-multilingual-base\n",
      "   10. ibm-granite/granite-embedding-30m-english\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. sentence-transformers/all-MiniLM-L6-v2\n",
      "   2. sentence-transformers/all-mpnet-base-v2\n",
      "   3. sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "   4. sentence-transformers/paraphrase-MiniLM-L6-v2\n",
      "   5. sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "   6. sentence-transformers/all-MiniLM-L12-v2\n",
      "   7. nomic-ai/nomic-embed-text-v1.5\n",
      "   8. Alibaba-NLP/gte-large-en-v1.5\n",
      "   9. upskyy/bge-m3-korean\n",
      "   10. Alibaba-NLP/gte-multilingual-base\n",
      "   11. tencent/Youtu-Embedding\n",
      "   12. ibm-granite/granite-embedding-125m-english\n",
      "   13. ibm-granite/granite-embedding-278m-multilingual\n",
      "   14. sentence-transformers/stsb-xlm-r-multilingual\n",
      "   15. ibm-granite/granite-embedding-30m-english\n",
      "\n",
      "ðŸ“‹ Language Modeling OR Chatbots OR Text Generation  (tag: text-generation)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. openai-community/gpt2\n",
      "   2. facebook/opt-125m\n",
      "   3. Qwen/Qwen2.5-3B-Instruct\n",
      "   4. meta-llama/Llama-3.1-8B-Instruct\n",
      "   5. Qwen/Qwen2.5-7B-Instruct\n",
      "   6. meta-llama/Llama-3.2-1B-Instruct\n",
      "   7. openai/gpt-oss-20b\n",
      "   8. Qwen/Qwen3-0.6B\n",
      "   9. google/gemma-3-1b-it\n",
      "   10. Qwen/Qwen3-32B\n",
      "Top 10 by trending_score:\n",
      "   1. deepseek-ai/DeepSeek-V3.2-Exp\n",
      "   2. deepseek-ai/DeepSeek-V3.1-Terminus\n",
      "   3. Alibaba-NLP/Tongyi-DeepResearch-30B-A3B\n",
      "   4. LiquidAI/LFM2-2.6B\n",
      "   5. Kwaipilot/KAT-Dev\n",
      "   6. Qwen/Qwen3-Next-80B-A3B-Instruct\n",
      "   7. openai/gpt-oss-20b\n",
      "   8. LiquidAI/LFM2-1.2B-RAG\n",
      "   9. meituan-longcat/LongCat-Flash-Thinking\n",
      "   10. LiquidAI/LFM2-1.2B-Extract\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. openai-community/gpt2\n",
      "   2. facebook/opt-125m\n",
      "   3. Qwen/Qwen2.5-3B-Instruct\n",
      "   4. meta-llama/Llama-3.1-8B-Instruct\n",
      "   5. Qwen/Qwen2.5-7B-Instruct\n",
      "   6. meta-llama/Llama-3.2-1B-Instruct\n",
      "   7. openai/gpt-oss-20b\n",
      "   8. Qwen/Qwen3-0.6B\n",
      "   9. google/gemma-3-1b-it\n",
      "   10. Qwen/Qwen3-32B\n",
      "   11. deepseek-ai/DeepSeek-V3.2-Exp\n",
      "   12. deepseek-ai/DeepSeek-V3.1-Terminus\n",
      "   13. Alibaba-NLP/Tongyi-DeepResearch-30B-A3B\n",
      "   14. LiquidAI/LFM2-2.6B\n",
      "   15. Kwaipilot/KAT-Dev\n",
      "   16. Qwen/Qwen3-Next-80B-A3B-Instruct\n",
      "   17. LiquidAI/LFM2-1.2B-RAG\n",
      "   18. meituan-longcat/LongCat-Flash-Thinking\n",
      "   19. LiquidAI/LFM2-1.2B-Extract\n",
      "\n",
      "ðŸ“‹ Machine Translation  (tag: translation)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. google-t5/t5-small\n",
      "   2. google-t5/t5-3b\n",
      "   3. google-t5/t5-base\n",
      "   4. Helsinki-NLP/opus-mt-fr-en\n",
      "   5. Helsinki-NLP/opus-mt-en-fr\n",
      "   6. Helsinki-NLP/opus-mt-ru-en\n",
      "   7. Helsinki-NLP/opus-mt-zh-en\n",
      "   8. Helsinki-NLP/opus-mt-en-de\n",
      "   9. Helsinki-NLP/opus-mt-de-en\n",
      "   10. google/madlad400-3b-mt\n",
      "Top 10 by trending_score:\n",
      "   1. LiquidAI/LFM2-350M-ENJP-MT\n",
      "   2. LiquidAI/LFM2-350M-ENJP-MT-GGUF\n",
      "   3. tencent/Hunyuan-MT-7B\n",
      "   4. facebook/nllb-200-distilled-600M\n",
      "   5. google-t5/t5-small\n",
      "   6. google/madlad400-3b-mt\n",
      "   7. Prosho/sentinel-src-25\n",
      "   8. tencent/Hunyuan-MT-Chimera-7B\n",
      "   9. yanolja/YanoljaNEXT-Rosetta-20B\n",
      "   10. google-t5/t5-3b\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. google-t5/t5-small\n",
      "   2. google-t5/t5-3b\n",
      "   3. google-t5/t5-base\n",
      "   4. Helsinki-NLP/opus-mt-fr-en\n",
      "   5. Helsinki-NLP/opus-mt-en-fr\n",
      "   6. Helsinki-NLP/opus-mt-ru-en\n",
      "   7. Helsinki-NLP/opus-mt-zh-en\n",
      "   8. Helsinki-NLP/opus-mt-en-de\n",
      "   9. Helsinki-NLP/opus-mt-de-en\n",
      "   10. google/madlad400-3b-mt\n",
      "   11. LiquidAI/LFM2-350M-ENJP-MT\n",
      "   12. LiquidAI/LFM2-350M-ENJP-MT-GGUF\n",
      "   13. tencent/Hunyuan-MT-7B\n",
      "   14. facebook/nllb-200-distilled-600M\n",
      "   15. Prosho/sentinel-src-25\n",
      "   16. tencent/Hunyuan-MT-Chimera-7B\n",
      "   17. yanolja/YanoljaNEXT-Rosetta-20B\n",
      "\n",
      "ðŸ“‹ Text Summarization  (tag: summarization)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. facebook/bart-large-cnn\n",
      "   2. sshleifer/distilbart-cnn-12-6\n",
      "   3. google/pegasus-xsum\n",
      "   4. philschmid/bart-large-cnn-samsum\n",
      "   5. sshleifer/distilbart-xsum-12-6\n",
      "   6. Falconsai/text_summarization\n",
      "   7. sshleifer/distilbart-cnn-6-6\n",
      "   8. csebuetnlp/mT5_multilingual_XLSum\n",
      "   9. google/pegasus-large\n",
      "   10. alaggung/bart-r3f\n",
      "Top 10 by trending_score:\n",
      "   1. facebook/bart-large-cnn\n",
      "   2. google/pegasus-cnn_dailymail\n",
      "   3. csebuetnlp/mT5_multilingual_XLSum\n",
      "   4. google/pegasus-xsum\n",
      "   5. ozcangundes/mt5-small-turkish-summarization\n",
      "   6. philschmid/bart-large-cnn-samsum\n",
      "   7. kriton/greek-text-summarization\n",
      "   8. eenzeenee/t5-base-korean-summarization\n",
      "   9. ARTeLab/it5-summarization-fanpage-64\n",
      "   10. ARTeLab/it5-summarization-fanpage\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. facebook/bart-large-cnn\n",
      "   2. sshleifer/distilbart-cnn-12-6\n",
      "   3. google/pegasus-xsum\n",
      "   4. philschmid/bart-large-cnn-samsum\n",
      "   5. sshleifer/distilbart-xsum-12-6\n",
      "   6. Falconsai/text_summarization\n",
      "   7. sshleifer/distilbart-cnn-6-6\n",
      "   8. csebuetnlp/mT5_multilingual_XLSum\n",
      "   9. google/pegasus-large\n",
      "   10. alaggung/bart-r3f\n",
      "   11. google/pegasus-cnn_dailymail\n",
      "   12. ozcangundes/mt5-small-turkish-summarization\n",
      "   13. kriton/greek-text-summarization\n",
      "   14. eenzeenee/t5-base-korean-summarization\n",
      "   15. ARTeLab/it5-summarization-fanpage-64\n",
      "   16. ARTeLab/it5-summarization-fanpage\n",
      "\n",
      "ðŸ“‹ Information Extraction  (tag: question-answering)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. deepset/roberta-base-squad2\n",
      "   2. monologg/koelectra-small-v2-distilled-korquad-384\n",
      "   3. dmis-lab/biobert-large-cased-v1.1-squad\n",
      "   4. distilbert/distilbert-base-cased-distilled-squad\n",
      "   5. deepset/bert-large-uncased-whole-word-masking-squad2\n",
      "   6. google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\n",
      "   7. distilbert/distilbert-base-uncased-distilled-squad\n",
      "   8. deepset/xlm-roberta-large-squad2\n",
      "   9. deepset/bert-base-cased-squad2\n",
      "   10. google-bert/bert-large-cased-whole-word-masking-finetuned-squad\n",
      "Top 10 by trending_score:\n",
      "   1. innocent-charles/Swahili-question-answer-latest-cased\n",
      "   2. distilbert/distilbert-base-uncased-distilled-squad\n",
      "   3. huggingface-course/bert-finetuned-squad\n",
      "   4. Hongbin37/CBT-LLM\n",
      "   5. incidelen/convbert-base-turkish-cased-qa\n",
      "   6. TIGER-Lab/general-verifier\n",
      "   7. incidelen/bert-base-turkish-cased-medical-qa\n",
      "   8. incidelen/bert-base-turkish-128k-cased-medical-qa\n",
      "   9. Jackrong/gpt-oss-120b-Distill-Phi-4-14B\n",
      "   10. MOHAMMED7M7/AI_Doctor_V1\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. deepset/roberta-base-squad2\n",
      "   2. monologg/koelectra-small-v2-distilled-korquad-384\n",
      "   3. dmis-lab/biobert-large-cased-v1.1-squad\n",
      "   4. distilbert/distilbert-base-cased-distilled-squad\n",
      "   5. deepset/bert-large-uncased-whole-word-masking-squad2\n",
      "   6. google-bert/bert-large-uncased-whole-word-masking-finetuned-squad\n",
      "   7. distilbert/distilbert-base-uncased-distilled-squad\n",
      "   8. deepset/xlm-roberta-large-squad2\n",
      "   9. deepset/bert-base-cased-squad2\n",
      "   10. google-bert/bert-large-cased-whole-word-masking-finetuned-squad\n",
      "   11. innocent-charles/Swahili-question-answer-latest-cased\n",
      "   12. huggingface-course/bert-finetuned-squad\n",
      "   13. Hongbin37/CBT-LLM\n",
      "   14. incidelen/convbert-base-turkish-cased-qa\n",
      "   15. TIGER-Lab/general-verifier\n",
      "   16. incidelen/bert-base-turkish-cased-medical-qa\n",
      "   17. incidelen/bert-base-turkish-128k-cased-medical-qa\n",
      "   18. Jackrong/gpt-oss-120b-Distill-Phi-4-14B\n",
      "   19. MOHAMMED7M7/AI_Doctor_V1\n",
      "\n",
      "ðŸ“‹ Speech Recognition  (tag: automatic-speech-recognition)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Top 10 by downloads:\n",
      "   1. openai/whisper-large-v3\n",
      "   2. openai/whisper-large-v3-turbo\n",
      "   3. jonatasgrosman/wav2vec2-large-xlsr-53-russian\n",
      "   4. MahmoudAshraf/mms-300m-1130-forced-aligner\n",
      "   5. jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\n",
      "   6. facebook/wav2vec2-base-960h\n",
      "   7. openai/whisper-small\n",
      "   8. distil-whisper/distil-large-v3\n",
      "   9. jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn\n",
      "   10. openai/whisper-small.en\n",
      "Top 10 by trending_score:\n",
      "   1. openai/whisper-large-v3\n",
      "   2. openai/whisper-large-v3-turbo\n",
      "   3. openai/whisper-small\n",
      "   4. NCAIR1/Yoruba-ASR\n",
      "   5. Vikhrmodels/Borealis\n",
      "   6. openai/whisper-tiny\n",
      "   7. prj-beatrice/japanese-hubert-base-phoneme-ctc-v3\n",
      "   8. facebook/wav2vec2-base-960h\n",
      "   9. nyrahealth/CrisperWhisper\n",
      "   10. kotoba-tech/kotoba-whisper-v2.2\n",
      "\n",
      "Merged (unique up to 20):\n",
      "   1. openai/whisper-large-v3\n",
      "   2. openai/whisper-large-v3-turbo\n",
      "   3. jonatasgrosman/wav2vec2-large-xlsr-53-russian\n",
      "   4. MahmoudAshraf/mms-300m-1130-forced-aligner\n",
      "   5. jonatasgrosman/wav2vec2-large-xlsr-53-portuguese\n",
      "   6. facebook/wav2vec2-base-960h\n",
      "   7. openai/whisper-small\n",
      "   8. distil-whisper/distil-large-v3\n",
      "   9. jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn\n",
      "   10. openai/whisper-small.en\n",
      "   11. NCAIR1/Yoruba-ASR\n",
      "   12. Vikhrmodels/Borealis\n",
      "   13. openai/whisper-tiny\n",
      "   14. prj-beatrice/japanese-hubert-base-phoneme-ctc-v3\n",
      "   15. nyrahealth/CrisperWhisper\n",
      "   16. kotoba-tech/kotoba-whisper-v2.2\n",
      "\n",
      "======================================================================\n",
      "âœ… Completed in 2.6s\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import list_models\n",
    "import time\n",
    "\n",
    "nlp_tasks = {\n",
    "    \"Text Classification\": \"zero-shot-classification\",\n",
    "    \"Named Entity Recognition (NER) OR Part-of-Speech Tagging (POS)\": \"token-classification\",\n",
    "    \"Sentiment Analysis\": \"text-classification\",\n",
    "    \"Semantic Analysis\": \"sentence-similarity\",\n",
    "    \"Language Modeling OR Chatbots OR Text Generation\": \"text-generation\",\n",
    "    \"Machine Translation\": \"translation\",\n",
    "    \"Text Summarization\": \"summarization\",\n",
    "    \"Information Extraction\": \"question-answering\",\n",
    "    \"Speech Recognition\": \"automatic-speech-recognition\",\n",
    "}\n",
    "\n",
    "print(\"ðŸ¤– Top 10 Models per NLP Task by trending_score and downloads\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "\n",
    "def get_models(pipeline_tag: str, sort: str, limit: int = 10):\n",
    "    \"\"\"Fetch models for a pipeline tag sorted by a metric (trending_score|downloads).\n",
    "\n",
    "    Updated: Uses direct keyword args (library=, pipeline_tag=) instead of ModelFilter.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        infos = list_models(\n",
    "            filter=\"transformers\", pipeline_tag=pipeline_tag, sort=sort, limit=limit\n",
    "        )\n",
    "        ids = []\n",
    "        for info in infos:\n",
    "            mid = getattr(info, \"modelId\", None) or getattr(info, \"id\", None)\n",
    "            if mid:\n",
    "                ids.append(mid)\n",
    "        return ids\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"   âŒ Error fetching models for '{pipeline_tag}' sorted by '{sort}': {e}\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "\n",
    "def merged_unique(top_trending: list, top_downloads: list, limit: int = 10):\n",
    "    \"\"\"Merge two lists, keeping order priority by trending first then downloads,\n",
    "    removing duplicates within the merged result, capped at limit.\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for lst in (top_trending, top_downloads):\n",
    "        for mid in lst:\n",
    "            if mid not in seen:\n",
    "                seen.add(mid)\n",
    "                out.append(mid)\n",
    "                if len(out) >= limit:\n",
    "                    return out\n",
    "    return out\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for task_name, pipeline_tag in nlp_tasks.items():\n",
    "    print(f\"\\nðŸ“‹ {task_name}  (tag: {pipeline_tag})\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    top_downloads = get_models(pipeline_tag, sort=\"downloads\", limit=10)\n",
    "    print(\"\\nTop 10 by downloads:\")\n",
    "    if top_downloads:\n",
    "        for i, model in enumerate(top_downloads, 1):\n",
    "            print(f\"   {i}. {model}\")\n",
    "    else:\n",
    "        print(\"   No models found for downloads\")\n",
    "\n",
    "    top_trending = get_models(pipeline_tag, sort=\"trending_score\", limit=10)\n",
    "    print(\"Top 10 by trending_score:\")\n",
    "    if top_trending:\n",
    "        for i, model in enumerate(top_trending, 1):\n",
    "            print(f\"   {i}. {model}\")\n",
    "    else:\n",
    "        print(\"   No models found for trending_score\")\n",
    "\n",
    "    merged = merged_unique(top_downloads, top_trending, limit=20)\n",
    "    print(\"\\nMerged (unique up to 20):\")\n",
    "    if merged:\n",
    "        for i, model in enumerate(merged, 1):\n",
    "            print(f\"   {i}. {model}\")\n",
    "    else:\n",
    "        print(\"   No models found for merged\")\n",
    "\n",
    "    time.sleep(0.1)  # be gentle to the API\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"âœ… Completed in {time.time() - start:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644988e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting models for: Named Entity Recognition (NER) (token-classification)\n",
      "\n",
      "Merged model list (up to 20 unique):\n",
      "  1. dslim/bert-base-NER\n",
      "  2. OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M\n",
      "  3. Babelscape/wikineural-multilingual-ner\n",
      "  4. CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy\n",
      "  5. Jean-Baptiste/camembert-ner\n",
      "  6. KoichiYasuoka/roberta-base-english-upos\n",
      "  7. KoichiYasuoka/roberta-large-english-upos\n",
      "  8. cahya/bert-base-indonesian-NER\n",
      "  9. jiaqianjing/chinese-address-ner\n",
      " 10. dslim/bert-large-NER\n",
      " 11. w11wo/indonesian-roberta-base-posp-tagger\n",
      " 12. dbmdz/bert-large-cased-finetuned-conll03-english\n",
      " 13. adibvafa/CodonTransformer\n",
      " 14. oliverguhr/fullstop-punctuation-multilang-large\n",
      " 15. tsmatz/xlm-roberta-ner-japanese\n",
      " 16. kredor/punctuate-all\n",
      " 17. cahya/NusaBert-ner-v1.3\n",
      " 18. OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M\n",
      " 19. Isotonic/distilbert_finetuned_ai4privacy_v2\n",
      "\n",
      "Validating first 20 models on sample text:\n",
      "Apple CEO Tim Cook met Elon Musk in Paris to discuss AI initiatives at the Louvre Museum. Microsoft and OpenAI representatives joined later in the afternoon.\n",
      "\n",
      "==========================================================================================\n",
      "Loading model: dslim/bert-base-NER\n",
      "WARNING:tensorflow:From c:\\Users\\Sinalocal\\anaconda3\\envs\\nlpenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 3.20s. Entities:\n",
      "  - Apple                ORG                score=0.998 span=(0,5)\n",
      "  - Tim Cook             PER                score=1.000 span=(10,18)\n",
      "  - Elon                 ORG                score=0.807 span=(23,27)\n",
      "  - Mu                   PER                score=0.520 span=(28,30)\n",
      "  - ##sk                 ORG                score=0.812 span=(30,32)\n",
      "  - Paris                LOC                score=1.000 span=(36,41)\n",
      "  - AI                   MISC               score=0.998 span=(53,55)\n",
      "  - Lou                  LOC                score=0.984 span=(75,78)\n",
      "  - ##vre Museum         LOC                score=0.983 span=(78,88)\n",
      "  - Microsoft            ORG                score=0.999 span=(90,99)\n",
      "  - OpenAI               ORG                score=0.991 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M\n",
      "Failed after 0.10s: ValueError: The repository OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M .\n",
      " You can inspect the repository content at https://hf.co/OpenMed/OpenMed-NER-ChemicalDetect-EuroMed-212M.\n",
      "Please pass the argument `trust_remote_code=True` to allow custom code to be run.\n",
      "==========================================================================================\n",
      "Loading model: Babelscape/wikineural-multilingual-ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 0.89s. Entities:\n",
      "  - Apple                ORG                score=0.998 span=(0,5)\n",
      "  - Tim Cook             PER                score=1.000 span=(10,18)\n",
      "  - Elon Musk            PER                score=0.998 span=(23,32)\n",
      "  - Paris                LOC                score=1.000 span=(36,41)\n",
      "  - Louvre Museum        LOC                score=0.998 span=(75,88)\n",
      "  - Microsoft            ORG                score=0.997 span=(90,99)\n",
      "  - OpenAI               ORG                score=0.942 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.44s. Entities:\n",
      "  - Apple                adj                score=0.986 span=(0,5)\n",
      "  - CEO                  noun_prop          score=0.944 span=(6,9)\n",
      "  - Tim                  noun               score=0.744 span=(10,13)\n",
      "  - Cook met             adj                score=0.783 span=(14,22)\n",
      "  - Elon Musk in Par     noun_prop          score=0.808 span=(23,39)\n",
      "  - ##is                 adj                score=0.514 span=(39,41)\n",
      "  - to discus            noun_prop          score=0.751 span=(42,51)\n",
      "  - ##s                  adj                score=0.539 span=(51,52)\n",
      "  - AI initiat           noun_prop          score=0.945 span=(53,63)\n",
      "  - ##ives               adj                score=0.620 span=(63,67)\n",
      "  - at                   noun_prop          score=0.421 span=(68,70)\n",
      "  - the                  abbrev             score=0.356 span=(71,74)\n",
      "  - Louv                 noun_prop          score=0.842 span=(75,79)\n",
      "  - ##re Museum          adj                score=0.785 span=(79,88)\n",
      "  - .                    punc               score=1.000 span=(88,89)\n",
      "  - Microsoft            adj                score=0.999 span=(90,99)\n",
      "  - and                  noun               score=1.000 span=(100,103)\n",
      "  - OpenAI representat   noun_prop          score=0.880 span=(104,122)\n",
      "  - ##ives joined later  adj                score=0.834 span=(122,139)\n",
      "  - in                   noun               score=0.566 span=(140,142)\n",
      "  - the aftern           noun_prop          score=0.964 span=(143,153)\n",
      "  - ##oon                adj                score=0.755 span=(153,156)\n",
      "  - .                    punc               score=1.000 span=(156,157)\n",
      "==========================================================================================\n",
      "Loading model: Jean-Baptiste/camembert-ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.01s. Entities:\n",
      "  - Apple                ORG                score=0.988 span=(0,5)\n",
      "  - Tim Cook             PER                score=0.999 span=(9,18)\n",
      "  - Elon Musk            PER                score=0.999 span=(22,32)\n",
      "  - Paris                LOC                score=0.998 span=(35,41)\n",
      "  - AI                   MISC               score=0.527 span=(52,55)\n",
      "  - Louvre Museum        LOC                score=0.995 span=(74,88)\n",
      "  - Microsoft            ORG                score=0.987 span=(89,99)\n",
      "  - OpenAI               ORG                score=0.556 span=(103,110)\n",
      "==========================================================================================\n",
      "Loading model: KoichiYasuoka/roberta-base-english-upos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.12s. Entities:\n",
      "  - Apple                PROPN              score=0.999 span=(0,5)\n",
      "  -  CEO                 NOUN               score=0.987 span=(6,9)\n",
      "  -  Tim Cook            PROPN              score=0.999 span=(10,18)\n",
      "  -  met                 VERB               score=1.000 span=(19,22)\n",
      "  -  Elon Musk           PROPN              score=0.999 span=(23,32)\n",
      "  -  in                  ADP                score=1.000 span=(33,35)\n",
      "  -  Paris               PROPN              score=0.999 span=(36,41)\n",
      "  -  to                  PART               score=0.999 span=(42,44)\n",
      "  -  discuss             VERB               score=1.000 span=(45,52)\n",
      "  -  AI                  PROPN              score=0.799 span=(53,55)\n",
      "  -  initiatives         NOUN               score=1.000 span=(56,67)\n",
      "  -  at                  ADP                score=1.000 span=(68,70)\n",
      "  -  the                 DET                score=1.000 span=(71,74)\n",
      "  -  Louvre Museum       PROPN              score=0.997 span=(75,88)\n",
      "  - .                    PUNCT              score=1.000 span=(88,89)\n",
      "  -  Microsoft           PROPN              score=0.999 span=(90,99)\n",
      "  -  and                 CCONJ              score=1.000 span=(100,103)\n",
      "  -  OpenAI              PROPN              score=0.998 span=(104,110)\n",
      "  -  representatives     NOUN               score=0.999 span=(111,126)\n",
      "  -  joined              VERB               score=1.000 span=(127,133)\n",
      "  -  later               ADV                score=0.993 span=(134,139)\n",
      "  -  in                  ADP                score=1.000 span=(140,142)\n",
      "  -  the                 DET                score=1.000 span=(143,146)\n",
      "  -  afternoon           NOUN               score=1.000 span=(147,156)\n",
      "  - .                    PUNCT              score=1.000 span=(156,157)\n",
      "==========================================================================================\n",
      "Loading model: KoichiYasuoka/roberta-large-english-upos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 2.74s. Entities:\n",
      "  - Apple                PROPN              score=1.000 span=(0,5)\n",
      "  -  CEO                 NOUN               score=0.996 span=(6,9)\n",
      "  -  Tim Cook            PROPN              score=1.000 span=(10,18)\n",
      "  -  met                 VERB               score=1.000 span=(19,22)\n",
      "  -  Elon Musk           PROPN              score=1.000 span=(23,32)\n",
      "  -  in                  ADP                score=1.000 span=(33,35)\n",
      "  -  Paris               PROPN              score=1.000 span=(36,41)\n",
      "  -  to                  PART               score=0.999 span=(42,44)\n",
      "  -  discuss             VERB               score=0.999 span=(45,52)\n",
      "  -  AI initiatives      NOUN               score=0.993 span=(53,67)\n",
      "  -  at                  ADP                score=1.000 span=(68,70)\n",
      "  -  the                 DET                score=1.000 span=(71,74)\n",
      "  -  Louvre Museum       PROPN              score=0.992 span=(75,88)\n",
      "  - .                    PUNCT              score=1.000 span=(88,89)\n",
      "  -  Microsoft           PROPN              score=1.000 span=(90,99)\n",
      "  -  and                 CCONJ              score=1.000 span=(100,103)\n",
      "  -  OpenAI              PROPN              score=0.998 span=(104,110)\n",
      "  -  representatives     NOUN               score=1.000 span=(111,126)\n",
      "  -  joined              VERB               score=1.000 span=(127,133)\n",
      "  -  later               ADV                score=0.998 span=(134,139)\n",
      "  -  in                  ADP                score=1.000 span=(140,142)\n",
      "  -  the                 DET                score=1.000 span=(143,146)\n",
      "  -  afternoon           NOUN               score=1.000 span=(147,156)\n",
      "  - .                    PUNCT              score=1.000 span=(156,157)\n",
      "==========================================================================================\n",
      "Loading model: cahya/bert-base-indonesian-NER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cahya/bert-base-indonesian-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.21s. Entities:\n",
      "  - apple ceo tim cook   ORG                score=0.906 span=(0,18)\n",
      "  - elon musk            PER                score=0.817 span=(23,32)\n",
      "  - paris                GPE                score=0.530 span=(36,41)\n",
      "  - the louvre museum    ORG                score=0.824 span=(71,88)\n",
      "  - microsoft            ORG                score=0.969 span=(90,99)\n",
      "  - openai               ORG                score=0.635 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: jiaqianjing/chinese-address-ner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccf566a8ca5486da0acea5830f4020d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/407M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0268692737ed48e68e69746fe70e6bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cf2aa14cdc44dc84a51a40c7d68779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c3a8a96c78484fb937d8c4a8cd0d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fad142976714870b15fb88f0ac34269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/407M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ca230f81334e94ae23340cd23438b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 9.01s. Entities:\n",
      "  - apple ceo tim cook me LABEL_14           score=0.289 span=(0,21)\n",
      "  - ##t el               LABEL_0            score=0.380 span=(21,25)\n",
      "  - ##on musk            LABEL_14           score=0.367 span=(25,32)\n",
      "  - in paris to discuss ai initiatives at the lou LABEL_0            score=0.710 span=(33,78)\n",
      "  - ##vr                 LABEL_14           score=0.442 span=(78,80)\n",
      "  - ##e                  LABEL_0            score=0.560 span=(80,81)\n",
      "  - museum               LABEL_14           score=0.574 span=(82,88)\n",
      "  - . microsoft and openai representatives joined later in the afternoon. LABEL_0            score=0.739 span=(88,157)\n",
      "==========================================================================================\n",
      "Loading model: dslim/bert-large-NER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b3d759c8dd41ba813348e469177368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67157b87c4b94d0babbfd184ab975c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9e965fb1274554976d50b79fc2b824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81c592041484f21a16bc9ba48729117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 21.18s. Entities:\n",
      "  - Apple                ORG                score=0.998 span=(0,5)\n",
      "  - Tim Cook             PER                score=1.000 span=(10,18)\n",
      "  - Elon Musk            PER                score=0.973 span=(23,32)\n",
      "  - Paris                LOC                score=1.000 span=(36,41)\n",
      "  - AI                   MISC               score=0.960 span=(53,55)\n",
      "  - Louvre Museum        LOC                score=0.985 span=(75,88)\n",
      "  - Microsoft            ORG                score=0.999 span=(90,99)\n",
      "  - OpenAI               ORG                score=0.917 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: w11wo/indonesian-roberta-base-posp-tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 0.77s. Entities:\n",
      "  -  Apple               NNP                score=0.990 span=(0,5)\n",
      "  -  CEO                 NNO                score=0.978 span=(6,9)\n",
      "  -  Tim                 NNO                score=0.971 span=(10,13)\n",
      "  -  Cook                NNP                score=0.991 span=(14,18)\n",
      "  -  met                 NNP                score=0.991 span=(19,22)\n",
      "  -  El                  NNP                score=0.998 span=(23,25)\n",
      "  - on                   NNP                score=0.926 span=(25,27)\n",
      "  -  Mus                 NNP                score=0.999 span=(28,31)\n",
      "  - k                    NNP                score=0.995 span=(31,32)\n",
      "  -  in                  PPO                score=0.994 span=(33,35)\n",
      "  -  Paris               NNP                score=0.971 span=(36,41)\n",
      "  -  to                  NNP                score=0.956 span=(42,44)\n",
      "  -  dis                 NNP                score=0.997 span=(45,48)\n",
      "  - cus                  NNP                score=0.990 span=(48,51)\n",
      "  - s                    NNP                score=0.963 span=(51,52)\n",
      "  -  AI                  NNP                score=0.996 span=(53,55)\n",
      "  -  in                  NNP                score=0.999 span=(56,58)\n",
      "  - iti                  NNP                score=0.999 span=(58,61)\n",
      "  - ativ                 NNP                score=0.990 span=(61,65)\n",
      "  - es                   NNP                score=0.937 span=(65,67)\n",
      "  -  at                  NNP                score=0.966 span=(68,70)\n",
      "  -  the                 NNO                score=0.977 span=(71,74)\n",
      "  -  Lou                 NNP                score=0.999 span=(75,78)\n",
      "  - v                    NNP                score=0.993 span=(78,79)\n",
      "  - re                   NNP                score=0.974 span=(79,81)\n",
      "  -  Museum              NNP                score=1.000 span=(82,88)\n",
      "  - .                    SYM                score=0.990 span=(88,89)\n",
      "  -  Microsoft           NNP                score=0.999 span=(90,99)\n",
      "  -  and                 CCN                score=1.000 span=(100,103)\n",
      "  -  Open                NNP                score=0.999 span=(104,108)\n",
      "  - AI                   NNP                score=0.995 span=(108,110)\n",
      "  -  represent           NNP                score=1.000 span=(111,120)\n",
      "  - ativ                 NNP                score=0.989 span=(120,124)\n",
      "  - es                   NNP                score=0.970 span=(124,126)\n",
      "  -  join                NNP                score=0.999 span=(127,131)\n",
      "  - ed                   NNP                score=0.824 span=(131,133)\n",
      "  -  l                   NNP                score=0.928 span=(134,135)\n",
      "  - ater                 NNO                score=0.692 span=(135,139)\n",
      "  -  in                  PPO                score=0.997 span=(140,142)\n",
      "  -  the                 NNO                score=0.994 span=(143,146)\n",
      "  -  af                  NNP                score=0.999 span=(147,149)\n",
      "  - tern                 NNP                score=0.999 span=(149,153)\n",
      "  - oon                  NNP                score=0.999 span=(153,156)\n",
      "  - .                    SYM                score=0.990 span=(156,157)\n",
      "==========================================================================================\n",
      "Loading model: dbmdz/bert-large-cased-finetuned-conll03-english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at adibvafa/CodonTransformer and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.50s. Entities:\n",
      "  - Apple                ORG                score=0.999 span=(0,5)\n",
      "  - Tim Cook             PER                score=1.000 span=(10,18)\n",
      "  - Elon Musk            PER                score=0.998 span=(23,32)\n",
      "  - Paris                LOC                score=1.000 span=(36,41)\n",
      "  - AI                   MISC               score=0.595 span=(53,55)\n",
      "  - Louvre Museum        LOC                score=0.927 span=(75,88)\n",
      "  - Microsoft            ORG                score=0.999 span=(90,99)\n",
      "  - OpenAI               ORG                score=0.992 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: adibvafa/CodonTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Attention type 'block_sparse' is not possible if sequence_length: 30 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 0.78s. Entities:\n",
      "  - Apple CEO Tim Cook met Elon Musk in Paris to discuss AI initiatives at the Louvre Museum . Microsoft and OpenAI representatives joined later in the afternoon . LABEL_1            score=0.766 span=(0,157)\n",
      "==========================================================================================\n",
      "Loading model: oliverguhr/fullstop-punctuation-multilang-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 2.36s. Entities:\n",
      "  - Apple CEO Tim Cook met Elon Musk in Paris to discuss AI initiatives at the Louvre 0                  score=0.958 span=(0,81)\n",
      "  - Museum               .                  score=0.521 span=(81,88)\n",
      "  - . Microsoft and OpenAI representatives joined later in the 0                  score=0.998 span=(88,146)\n",
      "  - afternoon.           .                  score=0.973 span=(146,157)\n",
      "==========================================================================================\n",
      "Loading model: tsmatz/xlm-roberta-ner-japanese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.75s. Entities:\n",
      "  - Apple                ORG                score=0.996 span=(0,5)\n",
      "  - Tim Cook             PER                score=0.980 span=(10,18)\n",
      "  - Elon Musk            PER                score=0.995 span=(23,32)\n",
      "  - Paris                LOC                score=0.979 span=(36,41)\n",
      "  - the Louvre Museum    INS                score=0.999 span=(71,88)\n",
      "  - Microsoft            ORG                score=0.997 span=(90,99)\n",
      "  - OpenAI               ORG                score=0.996 span=(104,110)\n",
      "==========================================================================================\n",
      "Loading model: kredor/punctuate-all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 4.65s. Entities:\n",
      "  - Apple CEO Tim Cook met Elon Musk in Paris to discuss AI initiatives at the Louvre Museum. Microsoft and OpenAI representatives joined later in the afternoon. 0                  score=0.955 span=(0,157)\n",
      "==========================================================================================\n",
      "Loading model: cahya/NusaBert-ner-v1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 2.66s. Entities:\n",
      "  - Apple                ORG                score=0.814 span=(0,5)\n",
      "  -  Tim Cook            PER                score=0.992 span=(9,18)\n",
      "  -  Elon Musk           PER                score=0.989 span=(22,32)\n",
      "  -  Paris               GPE                score=0.995 span=(35,41)\n",
      "  -  AI                  PRD                score=0.777 span=(52,55)\n",
      "  -  the Louvre Museum   LOC                score=0.821 span=(70,88)\n",
      "  -  Microsoft           ORG                score=0.944 span=(89,99)\n",
      "  -  OpenAI representatives ORG                score=0.805 span=(103,126)\n",
      "==========================================================================================\n",
      "Loading model: OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 1.90s. Entities:\n",
      "==========================================================================================\n",
      "Loading model: Isotonic/distilbert_finetuned_ai4privacy_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference succeeded in 0.52s. Entities:\n",
      "  - tim                  FIRSTNAME          score=0.942 span=(10,13)\n",
      "  - cook                 LASTNAME           score=0.979 span=(14,18)\n",
      "  - elon                 FIRSTNAME          score=0.972 span=(23,27)\n",
      "  - musk                 LASTNAME           score=0.965 span=(28,32)\n",
      "  - paris                STATE              score=0.741 span=(36,41)\n",
      "\n",
      "Saved validation summary -> results\\ner_validation_results.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "TASK_NAME = \"Named Entity Recognition (NER)\"\n",
    "PIPELINE_TAG = \"token-classification\"\n",
    "\n",
    "# 1. Collect merged model list (top trending + top downloads, unique)\n",
    "print(f\"Collecting models for: {TASK_NAME} ({PIPELINE_TAG})\")\n",
    "trend = get_models(PIPELINE_TAG, sort=\"trending_score\", limit=10)\n",
    "download = get_models(PIPELINE_TAG, sort=\"downloads\", limit=10)\n",
    "merged_models = merged_unique(trend, download, limit=20)\n",
    "\n",
    "print(\"\\nMerged model list (up to 20 unique):\")\n",
    "for i, m in enumerate(merged_models, 1):\n",
    "    print(f\" {i:2d}. {m}\")\n",
    "\n",
    "# 2. Quick validation on a sample text\n",
    "sample_text = (\n",
    "    \"Apple CEO Tim Cook met Elon Musk in Paris to discuss AI initiatives at the Louvre Museum. \"\n",
    "    \"Microsoft and OpenAI representatives joined later in the afternoon.\"\n",
    ")\n",
    "\n",
    "# Limit number of models to validate to keep runtime/resource usage reasonable.\n",
    "max_models = 20  # You can raise this after first quick check.\n",
    "print(f\"\\nValidating first {max_models} models on sample text:\\n{sample_text}\\n\")\n",
    "\n",
    "try:\n",
    "    import torch  # optional acceleration\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "except Exception:\n",
    "    device = -1\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for model_id in merged_models[:max_models]:\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"Loading model: {model_id}\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        try:\n",
    "            ner_pipe = pipeline(\n",
    "                PIPELINE_TAG,\n",
    "                model=model_id,\n",
    "                aggregation_strategy=\"simple\",  # prefer grouped entities\n",
    "                device=device,\n",
    "            )\n",
    "        except TypeError:\n",
    "            # Fallback if aggregation_strategy not supported at init\n",
    "            ner_pipe = pipeline(PIPELINE_TAG, model=model_id, device=device)\n",
    "\n",
    "        outputs = ner_pipe(sample_text)\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"Inference succeeded in {elapsed:.2f}s. Entities:\")\n",
    "\n",
    "        # Normalize output format\n",
    "        normalized = []\n",
    "        for ent in outputs:\n",
    "            word = ent.get(\"word\") or ent.get(\"entity\")\n",
    "            group = ent.get(\"entity_group\") or ent.get(\"entity\")\n",
    "            score = ent.get(\"score\", None)\n",
    "            start = ent.get(\"start\")\n",
    "            end = ent.get(\"end\")\n",
    "            normalized.append(\n",
    "                {\n",
    "                    \"word\": word,\n",
    "                    \"entity_group\": group,\n",
    "                    \"score\": float(score) if score is not None else None,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                }\n",
    "            )\n",
    "            display_score = f\"{score:.3f}\" if score is not None else \"-\"\n",
    "            print(\n",
    "                f\"  - {word:<20} {group:<18} score={display_score} span=({start},{end})\"\n",
    "            )\n",
    "\n",
    "        results_summary.append(\n",
    "            {\n",
    "                \"model\": model_id,\n",
    "                \"elapsed_seconds\": elapsed,\n",
    "                \"entities\": normalized,\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"Failed after {elapsed:.2f}s: {e.__class__.__name__}: {e}\")\n",
    "        results_summary.append(\n",
    "            {\n",
    "                \"model\": model_id,\n",
    "                \"error\": f\"{e.__class__.__name__}: {e}\",\n",
    "                \"elapsed_seconds\": elapsed,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# 3. Persist results to disk\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "out_path = os.path.join(\"results\", \"ner_validation_results.json\")\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nSaved validation summary ->\", out_path)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
